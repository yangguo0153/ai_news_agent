import re
from typing import List, Any

def suggest_policy_from_chat(message: str) -> dict:
    """
    Simulate an AI extraction of policy settings from natural language.
    Uses Regex for MVP to avoid needing API keys immediately.
    
    Returns a dict with found keys, e.g.:
    {
        "overtime_start_time": "20:00",
        "taxi_daily_limit": 300.0,
        "company_name": "New Corp"
    }
    """
    suggestions = {}
    
    # 1. Extract Overtime Start Time
    if "åŠ ç­" in message:
        # Match 19:00, 20:30
        hhmm_match = re.search(r'(\d{1,2}:\d{2})', message)
        if hhmm_match:
            suggestions["overtime_start_time"] = hhmm_match.group(1)
        else:
            # Match "8ç‚¹", "20ç‚¹"
            hour_match = re.search(r'(\d{1,2})\s*ç‚¹', message)
            if hour_match:
                hour = int(hour_match.group(1))
                if hour < 12 and ("æ™šä¸Š" in message or "ä¸‹åˆ" in message):
                    hour += 12
                elif hour < 9:
                    hour += 12
                suggestions["overtime_start_time"] = f"{hour:02d}:00"

    # 2. Extract Taxi Limit
    if "é™é¢" in message or "æŠ¥é”€" in message or "æ‰“è½¦" in message:
        limit_match = re.search(r'(?:é™é¢|ä¸è¶…è¿‡|ä¸Šé™|æœ€å¤š)\s*(\d+)', message)
        if limit_match:
            suggestions["taxi_daily_limit"] = float(limit_match.group(1))
        else:
            yuan_match = re.search(r'(\d+)\s*å…ƒ', message)
            if yuan_match:
                suggestions["taxi_daily_limit"] = float(yuan_match.group(1))
                 
    # 3. Extract Company Name
    company_match = re.search(r'(?:æˆ‘ä»¬|å…¬å¸)(?:å|åç§°)?(?:æ˜¯|å«|ä¸º|è®¾ç½®ä¸º)\s*([A-Za-z0-9\u4e00-\u9fa5]+)(?:å…¬å¸)?', message)
    if not company_match:
        company_match = re.search(r'æˆ‘æ˜¯([A-Za-z0-9\u4e00-\u9fa5]+)å…¬å¸çš„', message)
    if company_match:
        suggestions["company_name"] = company_match.group(1)

    return suggestions


def detect_template_selection(message: str, templates: List[Any]) -> dict:
    """
    Detect if user is trying to select a workflow template.
    Returns {"selected_template": template_obj} if match found.
    """
    message_lower = message.lower()
    
    # Check for template selection keywords
    selection_keywords = ["é€‰æ‹©", "ç”¨", "ä½¿ç”¨", "é€‰", "æˆ‘è¦", "å¸®æˆ‘"]
    has_selection_intent = any(kw in message for kw in selection_keywords)
    
    if has_selection_intent:
        for tpl in templates:
            # Match by template name
            if tpl.name in message:
                return {"selected_template": tpl}
            # Match by keywords in template name
            if "åŠ ç­" in message and "åŠ ç­" in tpl.name:
                return {"selected_template": tpl}
            if "å‡ºå·®" in message and "å‡ºå·®" in tpl.name:
                return {"selected_template": tpl}
    
    return {}


def get_ai_response(message: str, templates: List[Any] = None) -> dict:
    """
    Returns text response and structured data updates.
    Now supports workflow template awareness.
    """
    if templates is None:
        templates = []
    
    updates = suggest_policy_from_chat(message)
    template_result = detect_template_selection(message, templates)
    
    # Check for greeting or help request
    greeting_keywords = ["ä½ å¥½", "hi", "hello", "å¸®æˆ‘", "æ€ä¹ˆ", "å¦‚ä½•"]
    is_greeting = any(kw in message.lower() for kw in greeting_keywords)
    
    # Check for template list request
    list_keywords = ["æœ‰å“ªäº›", "ä»€ä¹ˆæµç¨‹", "ä»€ä¹ˆæ–¹æ¡ˆ", "åˆ—å‡º", "æŸ¥çœ‹"]
    wants_list = any(kw in message for kw in list_keywords)
    
    # Response Generation
    if wants_list and templates:
        template_list = "\n".join([f"â€¢ **{t.name}**: {t.description}" for t in templates])
        response_text = f"ç›®å‰æ”¯æŒä»¥ä¸‹æŠ¥é”€æµç¨‹ï¼š\n{template_list}\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³ä½¿ç”¨å“ªä¸ªæµç¨‹?"
        return {"text": response_text, "updates": {}, "action": "list_templates"}
    
    if template_result.get("selected_template"):
        tpl = template_result["selected_template"]
        response_text = f"å¥½çš„ï¼Œå·²ä¸ºæ‚¨é€‰æ‹©ã€{tpl.name}ã€‘æµç¨‹ã€‚\n\nğŸ“‹ éœ€è¦ä¸Šä¼ çš„ææ–™ï¼š{', '.join(tpl.required_files)}\n\nè¯·åœ¨å·¦ä¾§ä¸Šä¼ æ–‡ä»¶åç‚¹å‡»'å¼€å§‹å¤„ç†'ã€‚"
        updates["selected_workflow"] = tpl.name
        return {"text": response_text, "updates": updates, "action": "select_template"}
    
    if is_greeting and not updates:
        available = ", ".join([t.name for t in templates]) if templates else "åŠ ç­æ‰“è½¦æŠ¥é”€"
        response_text = f"ä½ å¥½ï¼æˆ‘æ˜¯æŠ¥é”€åŠ©æ‰‹ ğŸ¤–\n\næˆ‘å¯ä»¥å¸®ä½ ï¼š\n1. é…ç½®æŠ¥é”€è§„åˆ™ï¼ˆå¦‚åŠ ç­èµ·ç®—æ—¶é—´ã€æ‰“è½¦é™é¢ï¼‰\n2. é€‰æ‹©æŠ¥é”€æµç¨‹ï¼ˆç›®å‰æ”¯æŒï¼š{available}ï¼‰\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ï¼Œä¾‹å¦‚ï¼š\nâ€¢ 'æˆ‘ä»¬å…¬å¸æ™šä¸Š8ç‚¹åç®—åŠ ç­ï¼Œé™é¢200å…ƒ'\nâ€¢ 'æˆ‘è¦ç”¨åŠ ç­æ‰“è½¦æŠ¥é”€æµç¨‹'"
        return {"text": response_text, "updates": {}, "action": "greeting"}
    
    # Default: Settings extraction
    
    if updates:
        response_text = "å·²ä¸ºæ‚¨æ›´æ–°è®¾ç½®ï¼š"
        if "company_name" in updates:
            response_text += f"\n- å…¬å¸åç§°ï¼š{updates['company_name']}"
        if "overtime_start_time" in updates:
            response_text += f"\n- åŠ ç­èµ·ç®—ï¼š{updates['overtime_start_time']}"
        if "taxi_daily_limit" in updates:
            response_text += f"\n- æ‰“è½¦é™é¢ï¼š{updates['taxi_daily_limit']}å…ƒ"
    else:
        response_text = "æˆ‘æ˜¯æ‚¨çš„æŠ¥é”€è§„åˆ™é…ç½®åŠ©æ‰‹ã€‚æ‚¨å¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘è§„åˆ™ï¼Œä¾‹å¦‚ï¼š'åŠ ç­å¦‚æœæ˜¯æ™šä¸Š9ç‚¹ä»¥åï¼Œæ‰“è½¦é™é¢200å…ƒ'ã€‚"
        
    return {
        "response": response_text,
        "updates": updates,
        "selected_template_id": None
    }

def call_llm_for_intake(message: str, templates: List[Any], settings: Any) -> dict:
    """Call OpenAI compatible API for intent analysis"""
    import requests
    import json
    
    headers = {
        "Authorization": f"Bearer {settings.openai_api_key}",
        "Content-Type": "application/json"
    }
    
    # Construct context from templates
    templates_context = []
    for t in templates:
        templates_context.append({
            "id": t.id,
            "name": t.name,
            "desc": t.description
        })
        
    system_prompt = f"""
    You are a Reimbursement Assistant.
    Goal: Identify which reimbursement scenario matches the user's input.
    Available Templates: {json.dumps(templates_context, ensure_ascii=False)}
    
    Return JSON format only:
    {{
        "matched_template_id": int or null,
        "reasoning": "short explanation",
        "response_to_user": "Friendly response confirming the scenario and asking to proceed. Mention specific required files based on template description."
    }}
    If no match, ask determining questions.
    """
    
    payload = {
        "model": settings.model_name,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ],
        "temperature": 0.3
    }
    
    try:
        response = requests.post(f"{settings.openai_base_url}/chat/completions", headers=headers, json=payload, timeout=10)
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            # Try parsing JSON
            try:
                # Find JSON block if wrapped in markdown
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0]
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0]
                
                ai_data = json.loads(content.strip())
                return {
                    "matched_template_id": ai_data.get("matched_template_id"),
                    "template_name": next((t.name for t in templates if t.id == ai_data.get("matched_template_id")), ""),
                    "message": ai_data.get("response_to_user")
                }
            except:
                print(f"Failed to parse LLM JSON: {content}")
    except Exception as e:
        print(f"LLM Request Failed: {e}")
        
    raise Exception("LLM processing failed")


def analyze_intake_intent(message: str, templates: List[Any], settings: Any = None) -> dict:
    """
    Analyzes user message to determine which reimbursement template matches.
    Uses LLM if configured, otherwise falls back to Regex.
    """
    import json
    
    # 1. Try LLM if configured
    if settings and settings.openai_api_key:
        try:
            return call_llm_for_intake(message, templates, settings)
        except Exception as e:
            print(f"Falling back to Regex due to LLM error: {e}")
            
    # 2. Regex Fallback
    for tpl in templates:
        # Simple keyword matching
        keywords = []
        if "åŠ ç­" in tpl.name: keywords.extend(["åŠ ç­", "æ‰“è½¦", "æ™šå½’", "å‡ºç§Ÿ", "æ»´æ»´"])
        if "å‡ºå·®" in tpl.name: keywords.extend(["å‡ºå·®", "å·®æ—…", "æœºç¥¨", "é…’åº—", "ç«è½¦", "é«˜é“"])
        
        if any(kw in message for kw in keywords):
             req_files = json.loads(tpl.required_files_json) if hasattr(tpl, 'required_files_json') else []
             return {
                "matched_template_id": tpl.id,
                "template_name": tpl.name,
                "message": f"å¥½çš„ï¼Œè¿™å±äºã€{tpl.name}ã€‘åœºæ™¯ã€‚\næ ¹æ®è§„å®šï¼Œæ‚¨éœ€è¦å‡†å¤‡ä»¥ä¸‹ææ–™ï¼š\n" + "\n".join([f"- {f}" for f in req_files]) + "\n\nå‡†å¤‡å¥½äº†å—ï¼Ÿ"
            }
            
    # 3. No match found
    return {
        "matched_template_id": None,
        "template_name": None,
        "message": "æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç¡®è®¤è¯†åˆ«æ‚¨çš„åœºæ™¯ã€‚ç›®å‰æ”¯æŒï¼š\n" + "\n".join([f"- {t.name}" for t in templates]) + "\n\nè¯·å†è¯¦ç»†æè¿°ä¸€ä¸‹ï¼Ÿ"
    }
